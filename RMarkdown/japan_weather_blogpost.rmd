---
title: "Untitled"
author: "RN7"
date: "August 23, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Visualizing the Weather in Japan: A Sweltering Summer Story

I've lived in a few countries where talking (or more typically whinging) about the weather is a national past time so I took things one step further, by making a blog post about it! 

The past few months we've had an absolute hell of a summer here in Tokyo. It's not just hot, it's extremely humid here too making things doubly worse! As some kinda coping mechanism I've been using R to create cool visualizations throughout the summer. This post will be a place where I can show all of them along with the code. I will also cover methods of getting Japanese weather and spatial data using the `jmastas`, `riem`, and `jpndistrict` packages.

Let's Begin!

```{r encoding JP script, echo=FALSE}
source("../scripts/source_encoding_932.r")
options(encoding = "utf-8")
```

```{r packages, warning=FALSE, message=FALSE}
library(jpndistrict) # install GitHub version to get English names in jpnprefs
library(sf)
library(ggplot2)
library(dplyr)
library(tidyr)
library(purrr)
library(lubridate)
library(scales) # pretty_breaks()
library(rvest)
library(stringr)
library(riem)
library(polite)
library(ggrepel)
library(gganimate)
library(jmastats)
library(geofacet)
library(gghighlight) # gghighlight

# font packages
library(emojifont)
library(extrafont)
load.fontawesome()
library(extrafont)
loadfonts()
```

## Heatmap:: Tokyo average temperature (1876-2016)

Back in July, at the height of the summer heatwave, I came across []() visualization by Toyo Keizai News on Twitter. Interestingly they provided a `.json` file of the data so I wanted to try recreating this in R!

On one hand, we could just use the `jmastats` package that I mentioned earlier to grab the data ourselves but since I had never dealt with `.JSON` data before I felt it was as good time as any to finally dive into it. Also, why go through the trouble if you already have the data sitting right there for you?

Let's go through what we have to do:
- Use the `jsonlite` package to read in the data
- Set the names for each vector with the year it corresponds to. 
- Oddly some of the temperature values are factors so we need to change them into numeric
- Using another mapper function we assign a new `year` variable to each of the "temperature per year" dataframes with their respective years. Basically we're bringing the year label we created for each list into an explicit value in the single (combined) dataframe that we map as the output. 

```{r}
tokyo_his_temp <- jsonlite::read_json("../data/temperature.json", simplifyVector = TRUE)

tokyo_weather_df <- tokyo_his_temp %>% 
  set_names(nm = 1876:2018) %>% 
  map(~as.data.frame(.) %>% 
        modify_if(., is.factor, as.character) %>% 
        modify_if(., is.character, as.numeric)) %>% 
  map2_df(., names(.), ~ mutate(., year = .y)) %>% 
  rename(avg_temp = ".")
```

Now we have a very lengthy data frame with the temperatures and their respective year. Now we have to add in the specific month-day for each of the years. The heat map is going to be running from June 1st to September 30th, a span of 122 days. We can use the `seq.Date()` function to create a new variable of dates running from these two dates grouped by year. We'll leave out data from this year as I don't feel like waiting around for another 2 weeks!

```{r}
tokyo_weather_df <- tokyo_weather_df %>% 
  filter(year != 2018) %>% 
  group_by(year) %>% 
  mutate(
    date = seq.Date(from = as.Date("1876-06-01"), 
                    by = "day",
                    length = 122),
    date = format(date, "%m/%d")
  ) %>% 
  ungroup() %>% 
  mutate(year = as.numeric(year))

glimpse(tokyo_weather_df)
```

Great! Now we have the data we need for plotting!

So, the point of this heatmap visualization is to see the changes in temperature across time. We need to choose the right kind of color palette to emphasize the salient point we are trying to convey with this visualization. A great resource that I like to use is [colorbrewer2.org](colorbrewer2.org) where you can choose from a variety of classes and scales to fit your palette needs. The colors I chose came from the 8-class diverging palette, the website provides you with the #   codes you need to pass into the scale function. I also specify the breaks and labels for the color scale as well as for the 

```{r}
# colorbrewer2.org: diverging 8-class palette
cols <- rev(c('#d53e4f','#f46d43','#fdae61','#fee08b','#e6f598','#abdda4','#66c2a5','#3288bd'))

labels <- c("10", "12", "14", "16", "18", "20", "22", "24", "26", "28", "30", "32")

breaks <- c(seq(10, 32, by = 2))
```

The ggplot2 code I used was fairly straightforward, a nifty new package I started using was the `glue` package by Jim Hester, basically to get the text to form multiple lines in the plot (so I don't have to use the "\n" inside `paste()`). We'll see more uses of this in the other visualizations as well!

```{r plot tokyo summer, fig.height=8, fig.width=10}
# library(scales)
tokyo_weather_df %>% 
  ggplot(aes(x = date, y = year, fill = avg_temp)) +
  geom_tile() +
  scale_fill_gradientn(
    colours = cols,
    labels = labels,
    breaks = breaks,
    limits = c(11.1, 33.2)) +
  guides(fill = guide_colorbar(title = expression("Temperature " ( degree~C)),
                               reverse = FALSE,
                               title.position = "left",
                               label.position = "bottom",
                               nrow = 1)) +
  scale_y_reverse(limits = c(2017, 1876), expand = c(0, 0),
                  breaks = c(1876, seq(1880, 2015, by = 10), 2017)) +
  scale_x_discrete(breaks = c("06/01", "07/01", "08/01", "09/01", "09/30"),
                   labels = c("June 1st", "July 1st", "Aug. 1st", 
                              "Sept. 1st", "Sept. 30th")) +
  labs(title = "Summers in Tokyo are Getting Longer and Hotter (1876-2017)",
       subtitle = glue::glue("
          One Row = One Year, From June 1st to September 30th
          Average Temperature (Celsius)
          "),
       caption = "Data from Toyo Keizai News via Japan Meteorological Agency") +
  theme_minimal() +
  theme(text = element_text(family = "Roboto Condensed", size = 12),
        axis.title = element_blank(),
        panel.grid = element_blank(),
        legend.position = "bottom",
        legend.key.width = unit(3, "cm"),
        plot.margin=unit(c(1,1,1.5,1.2),"cm"))
```

Although Toyo Keizai says that the data is from JMA and the measure is the average temperature for that day, I don't know if the temperatures comes from the entirety of the Tokyo Prefecture (including the islands off the coast) or just from the 23 special wards that make up Tokyo City. It's not necessarily a huge concern but it is something to consider.

For those that want a more granular look I also created a Shiny app version of the above ([here]()) so you can scroll around and look at the temperature for a specific day.

## Tokyo Climate Stripes

Back in August I came across Ed Hawkins' cool climate strip visualization, again on Twitter. There were several versions out for different countries and cities but I didn't see Tokyo on there, so thinking it'll be a good opportunity for some practice I went ahead and tried to recreate it!

This time i'm getting data straight from JMA, the annual temperature table from this link [here](http://www.data.jma.go.jp/obd/stats/etrn/view/annually_s.php?prec_no=44&block_no=47662).

```{r}
url <- "http://www.data.jma.go.jp/obd/stats/etrn/view/annually_s.php?prec_no=44&block_no=47662"

session_jma <- url %>% 
  read_html() %>% 
  html_nodes("#tablefix1") %>% 
  .[[1]] %>% 
  html_table(fill = TRUE, header = FALSE)

```

Welp. What a giant mess of a table! Thankfully our trust `dplyr` verbs and `regex` can solve our problems. Et Voila!

```{r}
tokyo_year_avg_temp <- session_jma %>% 
  select(year = X1, avg_temp = X8, avg_high = X9, avg_low = X10, 
         high_temp = X11, low_temp = X12) %>% 
  slice(-c(1, 2, 3)) %>% 
  mutate(avg_temp = avg_temp %>% str_remove("\\]") %>% as.numeric(),
         avg_high = avg_high %>% str_remove("\\]") %>% as.numeric(),
         avg_low = avg_low %>% str_remove("\\]") %>% as.numeric(),
         high_temp = high_temp %>% str_remove("\\]") %>% as.numeric(),
         low_temp = low_temp %>% str_remove("\\]") %>% as.numeric(),
         year = forcats::as_factor(year))
```

I was wondering what kind of color palette Ed used... so going back to the Twitter thread I saw somebody opine that he might have used "10-class divergent RD-BU" from `colorbrewer2.org`. I checked it out and it seemed very similar so I went ahead and used that!

```{r}
# 10 Class Divergent Rd-Bu: http://colorbrewer2.org/#type=diverging&scheme=RdBu&n=10
temp_cols <- rev(c('#67001f','#b2182b','#d6604d','#f4a582','#fddbc7',
               '#d1e5f0','#92c5de','#4393c3','#2166ac','#053061'))
```

The plot was very simple. I used `geom_bar()` for the striples and specified width = 1 so that the bars left no gap in between each other and then erased all the axes and labels with `theme_void()`.

```{r climate stripe plot, fig.height=6, fig.width=8}
# filter out 1875 and 2018 due to uncertainties in the measurements

tokyo_year_avg_temp %>% 
  filter(!year %in% c(1875, 2018)) %>% 
  ggplot(aes(x = year, fill = avg_temp)) +
  geom_bar(position = "fill", width = 1) +
  scale_y_continuous(expand = c(0, 0.01)) +
  scale_x_discrete(expand = c(0, 0)) +
  scale_fill_gradientn(colors = temp_cols, "Average Temperature (Celsius)") +
  labs(title = "Tokyo: Annual Average Temperature (1876-2017)",
       subtitle = "One Stripe = One Year, Left: 1876, Right: 2017") +
  theme_void() +
  theme(text = element_text(family = "Roboto Condensed"),
        legend.position = "bottom",
        legend.title = element_text())

```

Very minimal yet very effective at showing the shift in temperature!

## Gathering Japanese Weather Data ft. RIEM & JMAStats


Grab data from: 

The [RIEM](https://github.com/ropensci/riem) package is an [ROpenSci](https://ropensci.org/) project that lets you download airport weather data from the Iowa Environmental Mesonet website. You can search for airport networks from all over the world and the Japan ASOS stations take measurements at 30 minute intervals so you get A LOT of data!

I found about this package last year and I even made a [blog post](https://ryo-n7.github.io/2017-11-22-japan-xkcd-weather-index/) using it as I wanted to create XKCD-themed charts showing where the most comfortable place (weather-wise) to live in Japan was. In the example I'll go over below I'll just be using the same set of Japanese airports I used back then, the top 50 busiest airports in Japan. I feel like it's a fair representation across the prefectures and I could use the "list of airports in Japan" wiki page but that has a lot of small airports and military base airports that wouldn't really be appropriate. 

A few minor changes were necessary however as oddly I can't seem to get the data from any of the Nagoya airports through this package nor the API on the Iowa Environmental Mesonet website...they used to work when i did the XKCD blog post a year ago but whatever, We'll skip over those for now. We'll just use RJGG which is the CHubu CEntrair  and it's the officially Nagoya (and the CHubu regions')  international airport nowadays anyways...

```{r RIEM}
# web scrape busiest Japan airport codes
session <- bow("https://en.wikipedia.org/wiki/List_of_the_busiest_airports_in_Japan")

japan_airports <- scrape(session) %>% 
  html_nodes("table.wikitable:nth-child(8)") %>% 
  .[[1]] %>% 
  html_table()

japan_airports_clean <- japan_airports %>% 
  janitor::clean_names() %>% 
  mutate(city = cityserved %>% iconv(from = "UTF-8", to = "ASCII//TRANSLIT")) %>% 
  select(airport, city, iata_icao) %>% 
  separate(iata_icao, c("IATA", "ICAO"), "\\/") %>% 
  mutate(city = case_when(
    ICAO == "RJAH" ~ "Ibaraki",            # fix Ibaraki Airport listed as Tokyo
    ICAO == "RJOK" ~ "Kochi",              # fix Kochi, Kochi to Kochi
    TRUE ~ city
  )) %>% 
  # filter out Narita and Kansai Airports
  # filter out RJNA (Nagoya) as not working for some reason
  # RJGG is also Nagoya so I'll use that instead
  filter(!ICAO %in% c("RJAA", "RJBB", "RJNA"))

```

Now that we have the ICAO codes for the Japanese airports we want, we can pass these codes into the `riem_measures()` function along with the date range. We use a mapper function `map_df()` as we want to iterate over all the airport codes in one go.

```{r}
# grab weather data from stations
summer_weather_riem_raw <-  
  map_df(japan_airports_clean$ICAO, riem_measures,
         date_start = "2018-06-01",
         date_end = "2018-08-31")

#saveRDS(summer_weather_riem_raw, file = "../data/summer_weather_riem_raw.RDS")
```

Great! Now we can do a bit of cleaning and also calculate the daily averages for a few temperature related measures as what `riem_measures()` gives us is a bit too granular for our purposes. Finally, combine it back with the airport data.

```{r join riem with station}
# calculate daily averages 
sum_air <- summer_weather_riem_raw %>% 
  mutate(time = as_date(valid) %>% ymd()) %>% 
  separate(time, into = c("year", "month", "day"), sep = "-") %>% 
  group_by(month, day, station) %>% 
  summarize(avg_temp = mean(tmpf),
            max_temp = max(tmpf),
            min_temp = min(tmpf),
            avg_dewp = mean(dwpf)) %>% 
  ungroup() %>% 
  # join riem data with airport data
  left_join(japan_airports_clean, by = c("station" = "ICAO")) %>% 
  glimpse()
```

With that done we can play around with the data a bit like finding the dew point, humidity, or changing from Fahrenheit to Celsius with the help of the `weathermetrics` package.

```{r}
library(weathermetrics)
# convert from Fahrenheit to Celsius!
sum_air %>% 
  mutate_at(vars(contains("temp")), 
            ~convert_temperature(temperature = ., old_metric = "f", new_metric = "c")) %>% 
  select(contains("temp")) %>% 
  glimpse()
```

You can also calculate the humidex (index of comfort combining temperature and humidity) with the `comf` package:

```{r}
library(comf)

sum_air %>% 
  mutate_at(vars(contains("avg")), 
            ~convert_temperature(temperature = ., old_metric = "f", new_metric = "c")) %>% 
  mutate(humidex = calcHumx(ta = avg_temp, rh = avg_dewp))
```


I took out a lot of the other weather variables like wind direction, wind speed, visibility, pressure altimeter, etc. that you can get from RIEM as I was only interested in the temperature stuff but you can see what each of them are from the [documentation](http://ropensci.github.io/riem/reference/riem_measures.html) or you can go directly to [Iowa Environmental Mesonet](https://mesonet.agron.iastate.edu/ASOS/) website to find more details.

## JMAStats package
- straight from the source! Japan Meteorological Agency
- still a work-in-progress package by @uribo
- i find navigating through japanese website to be a pain in the ass so this is a lifesaver!
- comes with some great color scales too!


uribo basically did >>> sample and take 1 station from each prefecture then grab data from those stations


First, let's create a small map of the JMA weather stations in Tokyo to give us a little context.

## Tokyo prefecture weather stations map

From here we can use the weather stations metadata from the `jmastats` package and filter for stations located in Tokyo. We'll select only those that are of type "四" or the AMeDAS stations that record temperature, precipitation, wind, and sunshine duration because this is the type of station I'll be using in the other visualizations. 

The Automated Meteorological Data Acquisition System (AMeDAS) is the 1,300 station network spread throughout Japan that uses automatic observation eqipment to measure and record data such as the weather, wind direction/speed, precipitation, humidity and more. There are both manned and unmanned stations which send data back to the JMA Headquarters at 10 second or 10 minutes intervals depending on the type of data.

Here's a picture of one of these AMeDAS installations:

![](https://i.imgur.com/SagQehX.jpg)

We'll also include the regional weather headquarters in Tokyo for this map (this station doesn't use AMeDAS).

```{r}
tky_stations_raw <- jmastats::stations %>% 
  filter(area == "東京") %>% 
  filter(station_type %in% c("四") | address == "千代田区北の丸公園　東京管区気象台")

tky_stations <- tky_stations_raw %>% 
  mutate(
    centroid = map(geometry, st_centroid),
    coords = map(centroid, st_coordinates),
    coord_x = map_dbl(coords, 1),
    coord_y = map_dbl(coords, 2)) %>% 
  select(-centroid, - coords)
```

There's still some islands but since they are part of districts on the mainland you can't just filter them out like we did with the Ogasawara Islands so I'm going to use the "hacksaw" approach and just cut them out from our view by specifying the x and y limits (the coordinates).

Using the `jpn_pref()` function from the `jpndistrict` package we specify the spatial polygons data we want to grab. In the `pref_code` argument we pass **13** as that's the code for the Tokyo Prefecture. 

For the plot we'll use `fontawesome` to represent the weather stations with cool icons. There's no "weather station" icon so I just used something that looks like a buiding.

```{r tokyo_prefecture_polygons & map}
sf_pref13 <- jpn_pref(pref_code = 13) %>% 
    st_simplify(dTolerance = 0.0001) %>% 
    mutate(city_code = as.numeric(city_code)) %>% 
    filter(city_code != 13421) %>%  # filter out the Ogasawara Islands (waaayy off the coast)
    st_union() %>% 
    as.data.frame() %>% 
    mutate(jis_code = "13", prefecture = "Tokyo") %>% 
    magrittr::set_names(c("geometry", "jis_code", "prefecture")) %>% 
    st_as_sf()

tky_stations <- tky_stations %>% 
  mutate(label = fontawesome(c("fa-university")))

sf_pref13 %>% 
  ggplot() +
  geom_sf(fill = "white") +
  coord_sf(xlim = c(138.9, 139.95),
           ylim = c(35.47, 35.9)) +
  geom_label(data = tky_stations, 
             aes(x = coord_x, y = coord_y,
                 label = label),
             family = "fontawesome-webfont") +
  geom_label_repel(data = tky_stations,
             aes(x = coord_x, y = coord_y,
                 label = station_name),
             size = 3, nudge_y = -0.025) +
  theme_minimal() +
  theme(axis.title = element_blank(),
        axis.ticks = element_blank())

```

With that you can see that the type "四" weather stations in Tokyo Prefecture are pretty well spread throughout the area.

Now that we got a little bit of context we can move on to the      !

Let's focus on grabbing weather data from largely populated areas. So what we can do is to grab coordinates for each of prefecture capitals from the jpndistrict::`jpnprefs` database, then pass those coordinates into jmastats::`nearest_station()` function to find the closest stations based on the capital city coordinates. Finally, we use the `jma_collect()` function to grab weather data for those stations. 

```{r jmastats data}
jpnprefs <- jpndistrict::jpnprefs

tky <- jpnprefs %>% filter(jis_code == 13) # Tokyo Prefecture: 13

lat <- jpnprefs %>% select(capital_latitude) %>% as_vector()
lon <- jpnprefs %>% select(capital_longitude) %>% as_vector()

japan_stations_coords <- map2(lon, lat, 
                              ~ nearest_station(longitude = .x, latitude = .y, 
                                                geometry = NULL))

# saveRDS(japan_one_stations, file = "../data/japan_stations_coords.RDS")

j_stat_ref <- japan_stations_coords %>% 
  map(~as.data.frame(.)) %>% 
  reduce(rbind) 
```

Interestingly, the `nearest_stations()` function gives us a new column in our dataframe showing how far away the station is from the coordinates we supplied it with. let's take a look at the average distance of each station from each prefecture capital!

```{r}
j_stat_ref %>% 
  summarize(avg_distance = mean(distance) %>% units::set_units(km))
```

So on average the stations were ~2.2 km away from the prefecture capital coordinates we gave the `nearest_stations()` function, looks good to me!

```{r}
j_station_df <- j_stat_ref %>% 
  select(-geometry) %>% 
  left_join(stations %>% st_set_geometry(NULL), by = c("station_no", "area", "station_name")) %>% 
  distinct(station_name, .keep_all = TRUE) %>%  # erase duplicate stations from joining
  glimpse()
```

We now have one station per prefecture that is as close to each capital city as possible!

Now we can use the `jma_collect()` function to get data from each station for each of the summer months (June, July, and August). 

```{r jma_collect and map, warning=FALSE, message=FALSE}
month <- c(6, 7, 8) # June, July, August
block_no <- j_ws_df %>% select(block_no) %>% as_vector()

# create a dataframe consisting of every combination of month and station
df <- crossing(block_no, month) 

j_sum_weather_raw <- map2(.x = df$block_no, .y = df$month, 
        ~ jma_collect(item = "daily", block_no = .x, year = 2018, month = .y) %>% 
          mutate(block = .x))

#saveRDS(j_sum_weather_raw, file = "../data/j_all_weather_raw.RDS")

j_all_weather_df <- j_sum_weather_raw %>% 
  bind_rows() %>% 
  select(1, 17, 5, 6, 7) %>% 
  magrittr::set_colnames(c("date", "block", 
                         "temperature_average", "temperature_max", "temperature_min")) 

#saveRDS(j_all_weather_df, file = "../data/j_all_weather_df.RDS")

# stations metadata
stations_df <- jmastats::stations %>% 
  select(pref_code, block_no, station_name, station_no, area) %>% 
  st_set_geometry(NULL) # no need for the station coordinate data now

# combine to get prefecture codes for each station
j_temp_stations_df <- j_all_weather_df %>% 
  left_join(stations_df, by = c("block" = "block_no")) %>% 
  # warning: some stations have same coordinates for 2 types...
  distinct(block, date, .keep_all = TRUE) %>% 
  mutate(pref_code = as.numeric(pref_code)) %>% 
  left_join(jpnprefs %>% mutate(jis_code = as.numeric(jis_code)),
            by = c("pref_code" = "jis_code")) %>% 
  select(-contains("capital_l"))
```

So now we have a large data frame for one station per prefecture from June to September!

We can also add in spatial polygons data (from `jpndistrict`) to create maps:

```{r combine with spatial}
# Japan polygons from jpndistrict package
sf_ja <- 1:47 %>% 
    map(~jpndistrict::jpn_pref(pref_code = ., district = FALSE)) %>% 
    reduce(rbind) %>% 
    st_simplify(dTolerance = 0.01) %>% 
  mutate(pref_code = as.numeric(pref_code))

j_temp_map_stations_df <- j_temp_stations_df %>% 
  mutate(pref_code = as.numeric(pref_code)) %>% 
  left_join(sf_ja, by = c("pref_code", "prefecture"))
```

The `jma_collect()` function gives us a lot of variables but depending on the station type some of these may not be filled in. 

I include a table here in English for the types of weather stations and in the github repo i included a comprehensive station info file as a PDF from the JMA (in Japanese)

```{r}

```

For my purposes I only wanted temperature data which is something nearly all station types collect so we are good to go! For those of you seeking other types weather data it is important that you read the documentation provided by the JMA. 

So, there's definitely a lot more steps compared to the RIEM package but on the other hand we are not limited to taking data only from weather stations at airports!


# Plotting weather data:

top 5 highest average temperature (averaged over the summer months period)?

gghighlight package

```{r typical bar plot}
cols <- c("Okinawa" = "#e41a1c", "Saga" = "#377eb8", 
          "Kagoshima" = "#4daf4a", "Kumamoto" = "#984ea3",
          "Gifu" = "#ff7f00")

j_temp_colors <- j_temp_stations_df %>% 
    mutate(prefecture_en = str_replace(prefecture_en, "\\-.*", ""))

j_temp_colors %>% 
  mutate(short_date = date %>% format(., "%b-%d")) %>% 
  ggplot() +
  geom_line(aes(x = date, y = temperature_average, color = prefecture_en)) +
  scale_color_manual(values = cols) +
  gghighlight(mean(temperature_average), max_highlight = 5) +
  scale_x_date(aes(date_labels = short_date)) +
  scale_y_continuous(breaks = scales::pretty_breaks(n = 5)) +
  labs(title = "Top 5 Prefectures with Highest Average Temperature (Celsius)", 
       subtitle = "Averaged over the summer months (June 1st - August 31st)",
       y = "Average Temperature (Celsius)") +
  theme_minimal() +
  theme(axis.title.x = element_blank())
```

no surprises with southern prefectures especially Okinawa!

with this view you can see clearly how okinawa is much hotter compared to the rest of japan during june and then you see the other prefectures "catching up" in July.


or let's look at things by region

- missing NAs throw off averaging...
- imputate with previous day's avg_temp?

- let's just take a look at teh temperature for the day of the summer solstice (for 2018 it's June 21st)


```{r}
j_temp_stations_df %>% 
  filter(date == "2018-06-21", region_en == "Kansai") %>% 
  mutate(region_avg_temp = mean(temperature_average)) %>% 
  mutate(perc = (((region_avg_temp - temperature_average) / 
                    (region_avg_temp + temperature_average) / 2) ) %>% 
           round(digits = 4)) %>% 
  ggplot(aes(x = perc, y = reorder(prefecture_en, perc))) +
  geom_segment(aes(x = perc, xend = 0,
                   yend = prefecture_en), 
               color = "skyblue")  +
  geom_point(aes(color = prefecture_en), show.legend = FALSE) +
  geom_vline(aes(xintercept = 0)) +
  scale_x_continuous(breaks = scales::pretty_breaks(n = 5), labels = percent) +
  labs(title = glue::glue(
    " Region on Summer Solstice"),
    subtitle = glue::glue("Vertical line: Average Temperature for  Region"),
    x = "Average Temperature (Celsius)",
    y = "Prefecture") +
  theme_minimal()
```






```{r lollipop plot by region avg}
region_plots <- j_temp_stations_df %>% 
  filter(date == "2018-06-21") %>% 
  # fill(temperature_average, .direction = "up") %>%  ## NOT needed for summer solstice date
  group_by(region_en) %>% 
  mutate(region_avg_temp = mean(temperature_average)) %>% 
  nest() %>% 
  #
  mutate(plot = map2(.x = region_en, .y = data, 
                     ~ ggplot(data = .y,
                              aes(x = temperature_average,
                                  y = reorder(prefecture_en, temperature_average))) +
                       geom_segment(aes(x = region_avg_temp, xend = temperature_average,
                                        yend = prefecture_en), 
                                    color = "skyblue") +
                       geom_point(aes(color = prefecture_en), show.legend = FALSE) +
                       geom_vline(aes(xintercept = region_avg_temp)) +
                       scale_x_continuous(breaks = scales::pretty_breaks(n = 10)) +
                       labs(title = glue::glue(
                         "{.x} Region on the Summer Solstice"),
                         subtitle = glue::glue(
                           "Vertical line: Average Temperature for {.x} Region"),
                         x = "Average Temperature (Celsius)",
                         y = "Prefecture") +
                       theme_minimal())
  )

walk(region_plots$plot, print)

```

These regions are divided into the officla regional divisions of Japan. Although they are not official administritative units in any shape or form things like weather reports use these regions to report the weather. We can see that with Okinawa being part of the Kyushu region it drastically skews the average while Hokkaido is the only prefecture in its region, so for a closer analysis it would be prudent to divide the prefectures differently!

We can look at bar graphs and other usual types but for those not familiar with japanese geography the results may not be obvious or unique or wouldn't provide much of a context

so let's try plotting this data on top of a map of japan!

```{r simple temp map}
# library(gganimate)
j_temp_map_stations_df %>% 
  #filter(date %in% as.Date( c("2018-06-20", "2018-06-21", "2018-06-22"))) %>% 
  ggplot() +
  geom_sf(aes(fill = temperature_average)) +
  scale_fill_gradientn(colours = jmastats:::jma_pal(
    palette = "relative", .attribute = FALSE)[6:1],
                            labels = c("35~", "30", "25", 
                                       "20",  "15", "10"),
                            breaks = c(35, 30, 25, 20, 15, 10),
                            limits = c(9, 35.5),
    name = "Average Temperature (Celsius)") +
  ggthemes::theme_map() +
  theme(legend.position = "right") +
  labs(title = "{closest_state}") +
  # transition_time(date)
  # animate
  transition_states(states = date, 
                    transition_length = 0.1, 
                    state_length = 0.35) +
  ease_aes('sine-in-out') 
```

animation >>> cycle through 3-day period


but hey, some parts of japan are pretty small and we can't really see the data too well

especially Tokyo or Okinawa

this is especially a problem for tokyo when you try to plot population data

take a look at this example

with tokyo being so populous, yet shows up as very small in terms of area size so it is not so easy to recognize at face-value


what can we do?


- use cartograms 

- instead use GEOFACETS!!!
now without the geographic area of each prefecture/city town obscuring our abilty

```{r}
pref_names <- j_temp_map_stations_df %>% 
  mutate(prefecture_en = str_replace(prefecture_en, "\\-.*", "")) %>% 
  distinct(pref_code, prefecture_en) %>% 
  arrange(pref_code) %>% 
  magrittr::use_series(prefecture_en)

jp_prefs_grid1 <- jp_prefs_grid1 %>% 
  arrange(code_pref_jis) %>% 
  mutate(prefecture_en = pref_names)
```



```{r fig.height=10, fig.width=12}
cols <- c("Kyushu" = "#e41a1c", "Shikoku" = "#377eb8", "Chugoku" = "#4daf4a", "Chubu" = "#984ea3",
          "Kansai" = "#ff7f00", "Kanto" = "#ffff33", "Tohoku" = "#a65628", "Hokkaido" = "#f781bf")

j_temp_colors %>% 
  ggplot(aes(date, temperature_average)) +
  geom_line(aes(color = region_en), show.legend = FALSE) +
  scale_color_manual(values = cols) +
  gghighlight(use_direct_label = FALSE) +
  theme(axis.title = element_blank(),
        panel.grid.minor = element_blank()) +
  facet_geo(~ prefecture_en, 
            grid = "jp_prefs_grid1")
```

as japan is such a thin long country you can really see the differences in temperature between the southern and northern prefectures!
we can properly gauage the differences while still maintaing geographic fidelity due to the positioning o the transformed squares/hexagons/facets!!

geofacet >>> simple line graph showing daily avg temperature across time? 


etc.




- https://www.nytimes.com/interactive/2018/08/30/climate/how-much-hotter-is-your-hometown.html

- Days @ or above 32 degrees Celsius per year
Tokyo (1993): 27 days
Tokyo (2018): 30 days 
Tokyo (2073): 43 days (39-58)

```{r}

```





- Tokyo Olympics 2020 >>> Marathon starting times fiasco (really? are we really going to 
do day light savings time for 2 months??? idiots.)
- select a time that's early but still advantageous for japanese runners
- 



on the other hand...

# Precipitation! Rain + Flooding in Western Japan!

typhoon season >>> WOrld CUp in 2002 had to be pushed earlier to avoid it!
well, some of it at least <Japan vs. Turkey pic>

Japan water basins?
- rayshader package

# Modeling? 
- i'm no expert but let's start with a somewhat naive approach?
- try more complicated techniques
- ... leave it to the experts lol

for NEXT time.







